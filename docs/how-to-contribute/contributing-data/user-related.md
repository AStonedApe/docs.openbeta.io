---
sidebar_position: 4
title: "User-Related Data"
sidebar_label: "Users and Opinion"
---

There are a handful of data points relating to users and how they engage with [Climbs](./climbs.md), [Areas](./areas.md), and [Media](./photos.md). These data don't generally reflect objective verifiable fact, but are nonetheless valuable to users and contributors alike.

## Ticks

Ticks are a common tool used by climbers to log their climbs. This helps them know where they've been and keep track of their progress. Tick lists are not always kept public, but when they are that data may be used to assess traffic for a given climb.

## Ratings

Ratings are the pinnacle of subjectivity, but are extremely valuable when trying to understand the quality of climbs in a dataset. Rating climbs as you tick them adds a lot to the dataset, and contributors are encouraged to give their opinion about a climb when they have one.

You need not send a route to give an opinion on it, as you can always update it at a later stage. That being said, the rating you provide is supposed to reflect your feeling about the climb, so contributors are expected to have some first-hand experience with the climb / area rather than logging one they have heard from another contributor.

## Media Engagement

Being able to tell between a helpful image and an unhelpful one is critical to ensuring that contributors get the most out of their effort. This is done through measuring user engagement with media by using [Comments](#Comments), [Upvotes, and Downvotes](#upvotes--downvotes).

Contributors are encouraged to engage authentically with media. Voting on the quality of media when they make use of it, and making use of moderation tools to keep inappropriate media out of the dataset

### Upvotes / Downvotes
These are a clear signal of opinion about media, and don't need much explaining as they are a familiar concept to anyone who uses social media.

## Comments
Comments serve a double-purpose for all kinds of entities. 

1. They appear as arbitrary discussion on supported entities, and allow communication about things that our developers have not captured through some other implementation.
Any time contributors have something to add to an entity - but are not certain if OpenBeta has a formal capture method for the observation - they are encouraged to add this observation in the form of a comment. This ensures that it is not lost, and provides other contributors with the opportunity to evaluate if the comment contains an observation that can be formally captured.

2. Comments **are** engagement, and as such can be used in the assessment of entry popularity. Not all comments are positive, but they can be used as an indicator of which entries contributors should be focused on improving / extending.
